{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Database for Crime Reports\n",
    "\n",
    "Using the data from `boston.csv`, a complication of crimes that occurred in Boston, we will construct a functional database with role permissions with `readonly` access for data analysts and `readwrite` for data scientists . \n",
    "\n",
    "Description of the data set by column:\n",
    "- `incident_number`: instance identifier of the crime\n",
    "- `offense_code`: numeric code type of the crime\n",
    "- `description`: brief of the crime committed\n",
    "- `date` & `day_of_the_week`: when the crime happened\n",
    "- `lat` & `long`: location of the crime with latitude and longitude coordinates\n",
    "\n",
    "## Creating the database and schema\n",
    "\n",
    "First we will build a database called `crime_db` by connecting to our existing database `dq`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "#conn.close()\n",
    "conn = psycopg2.connect(\"dbname=dq user=dq\")\n",
    "# set autocommit to True to create database\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE DATABASE crime_db;\")\n",
    "conn.autocommit = False\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will create a schema named `crimes` for storing the tables of crime data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\"dbname=crime_db user=dq\")\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE SCHEMA crimes;\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the column names and sample first row\n",
    "\n",
    "By obtaining the column headers and first row of data as variables, we can more easily explore the data and build the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"boston.csv\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    col_headers = next(reader)\n",
    "    first_row = next(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the column values\n",
    "\n",
    "Identifying the proper datatypes for each column will be essential before building our table. So we shall construct a function to do this work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incident_number\t298329\n",
      "offense_code\t219\n",
      "description\t239\n",
      "date\t1177\n",
      "day_of_the_week\t7\n",
      "lat\t18177\n",
      "long\t18177\n"
     ]
    }
   ],
   "source": [
    "def get_col_value_set(csv_filename, col_index):\n",
    "    values = set()\n",
    "    with open(csv_filename, 'r') as f:\n",
    "        next(f)\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            values.add(row[col_index])\n",
    "    return values\n",
    "\n",
    "for i in range(len(col_headers)):\n",
    "    values = get_col_value_set(\"boston.csv\", i)\n",
    "    print(col_headers[i], len(values), sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's use our `get_col_value_set()` function to get a set of text elements and determine which is the longest. Since `Wednesday` is known to be the longest of the `day_of_the_week` column, we shall focus our efforts on the `description` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n"
     ]
    }
   ],
   "source": [
    "# print the column headers to determine index value of description\n",
    "print(col_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "descriptions = get_col_value_set(\"boston.csv\", 2)\n",
    "max_len = 0\n",
    "for d in descriptions:\n",
    "    max_len = max(max_len, len(d))\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move forward, let's take another look at our column headers and the datatypes of the first row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['incident_number', 'offense_code', 'description', 'date', 'day_of_the_week', 'lat', 'long']\n",
      "['1', '619', 'LARCENY ALL OTHERS', '2018-09-02', 'Sunday', '42.35779134', '-71.13937053']\n"
     ]
    }
   ],
   "source": [
    "print(col_headers)\n",
    "print(first_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the table\n",
    "\n",
    "Based on our observations from above, we will use the type `INTEGER` for both `incident_number` and `offense_code`. `incident_number` will serve as our primary key.\n",
    "\n",
    "Since the `description` has at most 58 characters we will use the datatype `VARCHAR(100)` to represent it. This leaves some margins for larger, future values while not being so big that we will waste a lot of memory.\n",
    "\n",
    "We will create an enumerated datatype named `weekday` for the `day_of_the_week` since there there only seven possible values.\n",
    "\n",
    "The date is represented as the `DATE` datatype. Finally, for the latitude and longitude `DECIMAL` datatype will be used to capture the precision needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create the enumerated datatype for representing the weekday\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TYPE weekday AS ENUM ('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday');\n",
    "\"\"\")\n",
    "# create the table\n",
    "cur.execute(\"\"\"\n",
    "    CREATE TABLE crimes.boston_crimes (\n",
    "        incident_number INTEGER PRIMARY KEY,\n",
    "        offense_code INTEGER,\n",
    "        description VARCHAR(100),\n",
    "        date DATE,\n",
    "        day_of_the_week weekday,\n",
    "        lat decimal,\n",
    "        long decimal\n",
    "    );\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading crime data into our table\n",
    "\n",
    "We will use the `copy_expert` method to load the data quickly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298329\n"
     ]
    }
   ],
   "source": [
    "# load the data from boston.csv into the table boston_crimes that is in the crimes schema\n",
    "with open(\"boston.csv\") as f:\n",
    "    cur.copy_expert(\"COPY crimes.boston_crimes FROM STDIN WITH CSV HEADER;\", f)\n",
    "cur.execute(\"SELECT * FROM crimes.boston_crimes\")\n",
    "# print the number of rows to ensure that they were loaded\n",
    "print(len(cur.fetchall()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our users groups for data analysts and data scientists\n",
    "\n",
    "By following the least privilege principle, the first step in doing so is to make sure that there are no privileges inherited from the public group and on the public schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur.execute(\"REVOKE ALL ON SCHEMA public FROM public;\")\n",
    "cur.execute(\"REVOKE ALL ON DATABASE crime_db FROM public;\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's create our user `readonly` and `readwrite` groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the readonly group for data analysts\n",
    "cur.execute(\"CREATE GROUP readonly NOLOGIN;\")\n",
    "cur.execute(\"GRANT CONNECT ON DATABASE crime_db TO readonly;\")\n",
    "cur.execute(\"GRANT USAGE ON SCHEMA crimes TO readonly;\")\n",
    "cur.execute(\"GRANT SELECT ON ALL TABLES IN SCHEMA crimes TO readonly;\")\n",
    "\n",
    "# create the readwrite group for data scientists\n",
    "cur.execute(\"CREATE GROUP readwrite NOLOGIN;\")\n",
    "cur.execute(\"GRANT CONNECT ON DATABASE crime_db TO readwrite;\")\n",
    "cur.execute(\"GRANT USAGE ON SCHEMA crimes TO readwrite;\")\n",
    "cur.execute(\"GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA crimes TO readwrite;\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will create a user for each group. `data_analyst` will belong to the `readonly` group and `data_scientist` to `readwrite`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create user data_analyst and add to readonly group\n",
    "cur.execute(\"CREATE USER data_analyst WITH PASSWORD 'secret1';\")\n",
    "cur.execute(\"GRANT readonly TO data_analyst;\")\n",
    "\n",
    "# create user data_scientist and add to readwrite group\n",
    "cur.execute(\"CREATE USER data_scientist WITH PASSWORD 'secret2';\")\n",
    "cur.execute(\"GRANT readwrite TO data_scientist;\")\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the database setup\n",
    "\n",
    "We can use SQL queries to check whether the objects have been created and that users and groups have the right privileges. This requires you to know the Postgres internal tables. We can query the `pg_roles table` to inspect privileges related to the database and the `information_schema.table_privileges` table to inspect table privileges.\n",
    "\n",
    "In the pg_roles table we will check database related privileges and for that we will look at the following columns:\n",
    "\n",
    "- `rolname`: The name of the user / group that the privilege refers to.\n",
    "- `rolsuper`: Whether this user / group is a super user. It should be set to `False` on every user / group that we have created.\n",
    "- `rolcreaterole`: Whether user / group can create users, groups or roles. It should be `False` on every user / group that we have created.\n",
    "- `rolcreatedb`: Whether user / group can create databases. It should be `False` on every user / group that we have created.\n",
    "- `rolcanlogin`: Whether user / group can login. It should be `True` on the users and `False` on the groups that we have created.\n",
    "\n",
    "In the `information_schema.table_privileges` we will check privileges related to SQL queries on tables. We will list the privileges of each group that we have created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('readonly', False, False, False, False)\n",
      "('readwrite', False, False, False, False)\n",
      "('data_analyst', False, False, False, True)\n",
      "('data_scientist', False, False, False, True)\n",
      "\n",
      "('readonly', 'SELECT')\n",
      "('readwrite', 'INSERT')\n",
      "('readwrite', 'SELECT')\n",
      "('readwrite', 'UPDATE')\n",
      "('readwrite', 'DELETE')\n"
     ]
    }
   ],
   "source": [
    "# close the old connection to test with a brand new connection\n",
    "conn.close()\n",
    "\n",
    "conn = psycopg2.connect(dbname=\"crime_db\", user=\"dq\")\n",
    "cur = conn.cursor()\n",
    "# check users and groups\n",
    "cur.execute(\"\"\"\n",
    "    SELECT rolname, rolsuper, rolcreaterole, rolcreatedb, rolcanlogin FROM pg_roles\n",
    "    WHERE rolname IN ('readonly', 'readwrite', 'data_analyst', 'data_scientist');\n",
    "\"\"\")\n",
    "for user in cur:\n",
    "    print(user)\n",
    "conn.commit()\n",
    "print()\n",
    "# check privileges\n",
    "cur.execute(\"\"\"\n",
    "    SELECT grantee, privilege_type\n",
    "    FROM information_schema.table_privileges\n",
    "    WHERE grantee IN ('readonly', 'readwrite');\n",
    "\"\"\")\n",
    "for user in cur:\n",
    "    print(user)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
